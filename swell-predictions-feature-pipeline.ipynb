{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1939145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: hopsworks 2.6.0.dev1\n",
      "Uninstalling hopsworks-2.6.0.dev1:\n",
      "  Successfully uninstalled hopsworks-2.6.0.dev1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.1.5 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pyqtwebengine<5.13, which is not installed.\n",
      "spyder 5.1.5 requires pylint<2.10.0,>=2.5.0, but you have pylint 2.13.4 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y hopsworks\n",
    "    !pip install -U 'git+https://github.com/logicalclocks/hopsworks-api@main#egg=hopsworks&subdirectory=python' --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cdbcfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request  \n",
    "import re\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hopsworks\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca44a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this cell and fill in details if you are running your own Hopsworks cluster\n",
    "#key=\"\"\n",
    "#with open(\"api-key.txt\", \"r\") as f:\n",
    "#    key = f.read().rstrip()\n",
    "#os.environ['HOPSWORKS_PROJECT']=\"cjsurf\"\n",
    "#os.environ['HOPSWORKS_HOST']=\"35.187.178.84\"\n",
    "#os.environ['HOPSWORKS_API_KEY']=key    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13fe2886",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKFILL=False\n",
    "if os.environ.get('HOPSWORKS_BACKFILL') == \"True\":\n",
    "    BACKFILL=True\n",
    "hours=119\n",
    "version=10\n",
    "url=\"https://polar.ncep.noaa.gov/waves/WEB/gfswave.latest_run/plots/gfswave.62081.bull\"\n",
    "backfill_url=\"https://repo.hops.works/master/hopsworks-tutorials/data/cjsurf/swells-clean.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc73480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['height2',\n",
       " 'period2',\n",
       " 'direction2',\n",
       " 'hits_at2',\n",
       " 'height4',\n",
       " 'period4',\n",
       " 'direction4',\n",
       " 'hits_at4',\n",
       " 'height6',\n",
       " 'period6',\n",
       " 'direction6',\n",
       " 'hits_at6',\n",
       " 'height8',\n",
       " 'period8',\n",
       " 'direction8',\n",
       " 'hits_at8',\n",
       " 'height10',\n",
       " 'period10',\n",
       " 'direction10',\n",
       " 'hits_at10',\n",
       " 'height12',\n",
       " 'period12',\n",
       " 'direction12',\n",
       " 'hits_at12',\n",
       " 'height14',\n",
       " 'period14',\n",
       " 'direction14',\n",
       " 'hits_at14',\n",
       " 'height16',\n",
       " 'period16',\n",
       " 'direction16',\n",
       " 'hits_at16',\n",
       " 'height18',\n",
       " 'period18',\n",
       " 'direction18',\n",
       " 'hits_at18',\n",
       " 'height20',\n",
       " 'period20',\n",
       " 'direction20',\n",
       " 'hits_at20',\n",
       " 'height22',\n",
       " 'period22',\n",
       " 'direction22',\n",
       " 'hits_at22',\n",
       " 'height24',\n",
       " 'period24',\n",
       " 'direction24',\n",
       " 'hits_at24',\n",
       " 'height26',\n",
       " 'period26',\n",
       " 'direction26',\n",
       " 'hits_at26',\n",
       " 'height28',\n",
       " 'period28',\n",
       " 'direction28',\n",
       " 'hits_at28',\n",
       " 'height30',\n",
       " 'period30',\n",
       " 'direction30',\n",
       " 'hits_at30',\n",
       " 'height32',\n",
       " 'period32',\n",
       " 'direction32',\n",
       " 'hits_at32',\n",
       " 'height34',\n",
       " 'period34',\n",
       " 'direction34',\n",
       " 'hits_at34',\n",
       " 'height36',\n",
       " 'period36',\n",
       " 'direction36',\n",
       " 'hits_at36',\n",
       " 'height38',\n",
       " 'period38',\n",
       " 'direction38',\n",
       " 'hits_at38',\n",
       " 'height40',\n",
       " 'period40',\n",
       " 'direction40',\n",
       " 'hits_at40',\n",
       " 'height42',\n",
       " 'period42',\n",
       " 'direction42',\n",
       " 'hits_at42',\n",
       " 'height44',\n",
       " 'period44',\n",
       " 'direction44',\n",
       " 'hits_at44',\n",
       " 'height46',\n",
       " 'period46',\n",
       " 'direction46',\n",
       " 'hits_at46',\n",
       " 'height48',\n",
       " 'period48',\n",
       " 'direction48',\n",
       " 'hits_at48',\n",
       " 'height50',\n",
       " 'period50',\n",
       " 'direction50',\n",
       " 'hits_at50',\n",
       " 'height52',\n",
       " 'period52',\n",
       " 'direction52',\n",
       " 'hits_at52',\n",
       " 'height54',\n",
       " 'period54',\n",
       " 'direction54',\n",
       " 'hits_at54',\n",
       " 'height56',\n",
       " 'period56',\n",
       " 'direction56',\n",
       " 'hits_at56',\n",
       " 'height58',\n",
       " 'period58',\n",
       " 'direction58',\n",
       " 'hits_at58',\n",
       " 'height60',\n",
       " 'period60',\n",
       " 'direction60',\n",
       " 'hits_at60',\n",
       " 'height62',\n",
       " 'period62',\n",
       " 'direction62',\n",
       " 'hits_at62',\n",
       " 'height64',\n",
       " 'period64',\n",
       " 'direction64',\n",
       " 'hits_at64',\n",
       " 'height66',\n",
       " 'period66',\n",
       " 'direction66',\n",
       " 'hits_at66',\n",
       " 'height68',\n",
       " 'period68',\n",
       " 'direction68',\n",
       " 'hits_at68',\n",
       " 'height70',\n",
       " 'period70',\n",
       " 'direction70',\n",
       " 'hits_at70',\n",
       " 'height72',\n",
       " 'period72',\n",
       " 'direction72',\n",
       " 'hits_at72',\n",
       " 'height74',\n",
       " 'period74',\n",
       " 'direction74',\n",
       " 'hits_at74',\n",
       " 'height76',\n",
       " 'period76',\n",
       " 'direction76',\n",
       " 'hits_at76',\n",
       " 'height78',\n",
       " 'period78',\n",
       " 'direction78',\n",
       " 'hits_at78',\n",
       " 'height80',\n",
       " 'period80',\n",
       " 'direction80',\n",
       " 'hits_at80',\n",
       " 'height82',\n",
       " 'period82',\n",
       " 'direction82',\n",
       " 'hits_at82',\n",
       " 'height84',\n",
       " 'period84',\n",
       " 'direction84',\n",
       " 'hits_at84',\n",
       " 'height86',\n",
       " 'period86',\n",
       " 'direction86',\n",
       " 'hits_at86',\n",
       " 'height88',\n",
       " 'period88',\n",
       " 'direction88',\n",
       " 'hits_at88',\n",
       " 'height90',\n",
       " 'period90',\n",
       " 'direction90',\n",
       " 'hits_at90',\n",
       " 'height92',\n",
       " 'period92',\n",
       " 'direction92',\n",
       " 'hits_at92',\n",
       " 'height94',\n",
       " 'period94',\n",
       " 'direction94',\n",
       " 'hits_at94',\n",
       " 'height96',\n",
       " 'period96',\n",
       " 'direction96',\n",
       " 'hits_at96',\n",
       " 'height98',\n",
       " 'period98',\n",
       " 'direction98',\n",
       " 'hits_at98',\n",
       " 'height100',\n",
       " 'period100',\n",
       " 'direction100',\n",
       " 'hits_at100',\n",
       " 'height102',\n",
       " 'period102',\n",
       " 'direction102',\n",
       " 'hits_at102',\n",
       " 'height104',\n",
       " 'period104',\n",
       " 'direction104',\n",
       " 'hits_at104',\n",
       " 'height106',\n",
       " 'period106',\n",
       " 'direction106',\n",
       " 'hits_at106',\n",
       " 'height108',\n",
       " 'period108',\n",
       " 'direction108',\n",
       " 'hits_at108',\n",
       " 'height110',\n",
       " 'period110',\n",
       " 'direction110',\n",
       " 'hits_at110',\n",
       " 'height112',\n",
       " 'period112',\n",
       " 'direction112',\n",
       " 'hits_at112',\n",
       " 'height114',\n",
       " 'period114',\n",
       " 'direction114',\n",
       " 'hits_at114',\n",
       " 'height116',\n",
       " 'period116',\n",
       " 'direction116',\n",
       " 'hits_at116',\n",
       " 'height118',\n",
       " 'period118',\n",
       " 'direction118',\n",
       " 'hits_at118',\n",
       " 'height120',\n",
       " 'period120',\n",
       " 'direction120',\n",
       " 'hits_at120',\n",
       " 'height122',\n",
       " 'period122',\n",
       " 'direction122',\n",
       " 'hits_at122',\n",
       " 'height124',\n",
       " 'period124',\n",
       " 'direction124',\n",
       " 'hits_at124',\n",
       " 'height126',\n",
       " 'period126',\n",
       " 'direction126',\n",
       " 'hits_at126',\n",
       " 'height128',\n",
       " 'period128',\n",
       " 'direction128',\n",
       " 'hits_at128',\n",
       " 'height130',\n",
       " 'period130',\n",
       " 'direction130',\n",
       " 'hits_at130',\n",
       " 'height132',\n",
       " 'period132',\n",
       " 'direction132',\n",
       " 'hits_at132',\n",
       " 'height134',\n",
       " 'period134',\n",
       " 'direction134',\n",
       " 'hits_at134',\n",
       " 'height136',\n",
       " 'period136',\n",
       " 'direction136',\n",
       " 'hits_at136',\n",
       " 'height138',\n",
       " 'period138',\n",
       " 'direction138',\n",
       " 'hits_at138',\n",
       " 'height140',\n",
       " 'period140',\n",
       " 'direction140',\n",
       " 'hits_at140',\n",
       " 'height142',\n",
       " 'period142',\n",
       " 'direction142',\n",
       " 'hits_at142',\n",
       " 'height144',\n",
       " 'period144',\n",
       " 'direction144',\n",
       " 'hits_at144',\n",
       " 'height146',\n",
       " 'period146',\n",
       " 'direction146',\n",
       " 'hits_at146',\n",
       " 'height148',\n",
       " 'period148',\n",
       " 'direction148',\n",
       " 'hits_at148',\n",
       " 'height150',\n",
       " 'period150',\n",
       " 'direction150',\n",
       " 'hits_at150',\n",
       " 'height152',\n",
       " 'period152',\n",
       " 'direction152',\n",
       " 'hits_at152',\n",
       " 'height154',\n",
       " 'period154',\n",
       " 'direction154',\n",
       " 'hits_at154',\n",
       " 'height156',\n",
       " 'period156',\n",
       " 'direction156',\n",
       " 'hits_at156',\n",
       " 'height158',\n",
       " 'period158',\n",
       " 'direction158',\n",
       " 'hits_at158',\n",
       " 'height160',\n",
       " 'period160',\n",
       " 'direction160',\n",
       " 'hits_at160',\n",
       " 'height162',\n",
       " 'period162',\n",
       " 'direction162',\n",
       " 'hits_at162',\n",
       " 'height164',\n",
       " 'period164',\n",
       " 'direction164',\n",
       " 'hits_at164',\n",
       " 'height166',\n",
       " 'period166',\n",
       " 'direction166',\n",
       " 'hits_at166',\n",
       " 'height168',\n",
       " 'period168',\n",
       " 'direction168',\n",
       " 'hits_at168',\n",
       " 'height170',\n",
       " 'period170',\n",
       " 'direction170',\n",
       " 'hits_at170',\n",
       " 'height172',\n",
       " 'period172',\n",
       " 'direction172',\n",
       " 'hits_at172',\n",
       " 'height174',\n",
       " 'period174',\n",
       " 'direction174',\n",
       " 'hits_at174',\n",
       " 'height176',\n",
       " 'period176',\n",
       " 'direction176',\n",
       " 'hits_at176',\n",
       " 'height178',\n",
       " 'period178',\n",
       " 'direction178',\n",
       " 'hits_at178',\n",
       " 'height180',\n",
       " 'period180',\n",
       " 'direction180',\n",
       " 'hits_at180',\n",
       " 'height182',\n",
       " 'period182',\n",
       " 'direction182',\n",
       " 'hits_at182',\n",
       " 'height184',\n",
       " 'period184',\n",
       " 'direction184',\n",
       " 'hits_at184',\n",
       " 'height186',\n",
       " 'period186',\n",
       " 'direction186',\n",
       " 'hits_at186',\n",
       " 'height188',\n",
       " 'period188',\n",
       " 'direction188',\n",
       " 'hits_at188',\n",
       " 'height190',\n",
       " 'period190',\n",
       " 'direction190',\n",
       " 'hits_at190',\n",
       " 'height192',\n",
       " 'period192',\n",
       " 'direction192',\n",
       " 'hits_at192',\n",
       " 'height194',\n",
       " 'period194',\n",
       " 'direction194',\n",
       " 'hits_at194',\n",
       " 'height196',\n",
       " 'period196',\n",
       " 'direction196',\n",
       " 'hits_at196',\n",
       " 'height198',\n",
       " 'period198',\n",
       " 'direction198',\n",
       " 'hits_at198',\n",
       " 'height200',\n",
       " 'period200',\n",
       " 'direction200',\n",
       " 'hits_at200',\n",
       " 'height202',\n",
       " 'period202',\n",
       " 'direction202',\n",
       " 'hits_at202',\n",
       " 'height204',\n",
       " 'period204',\n",
       " 'direction204',\n",
       " 'hits_at204',\n",
       " 'height206',\n",
       " 'period206',\n",
       " 'direction206',\n",
       " 'hits_at206',\n",
       " 'height208',\n",
       " 'period208',\n",
       " 'direction208',\n",
       " 'hits_at208',\n",
       " 'height210',\n",
       " 'period210',\n",
       " 'direction210',\n",
       " 'hits_at210',\n",
       " 'height212',\n",
       " 'period212',\n",
       " 'direction212',\n",
       " 'hits_at212',\n",
       " 'height214',\n",
       " 'period214',\n",
       " 'direction214',\n",
       " 'hits_at214',\n",
       " 'height216',\n",
       " 'period216',\n",
       " 'direction216',\n",
       " 'hits_at216',\n",
       " 'height218',\n",
       " 'period218',\n",
       " 'direction218',\n",
       " 'hits_at218',\n",
       " 'height220',\n",
       " 'period220',\n",
       " 'direction220',\n",
       " 'hits_at220',\n",
       " 'height222',\n",
       " 'period222',\n",
       " 'direction222',\n",
       " 'hits_at222',\n",
       " 'height224',\n",
       " 'period224',\n",
       " 'direction224',\n",
       " 'hits_at224',\n",
       " 'height226',\n",
       " 'period226',\n",
       " 'direction226',\n",
       " 'hits_at226',\n",
       " 'height228',\n",
       " 'period228',\n",
       " 'direction228',\n",
       " 'hits_at228',\n",
       " 'height230',\n",
       " 'period230',\n",
       " 'direction230',\n",
       " 'hits_at230',\n",
       " 'height232',\n",
       " 'period232',\n",
       " 'direction232',\n",
       " 'hits_at232',\n",
       " 'height234',\n",
       " 'period234',\n",
       " 'direction234',\n",
       " 'hits_at234',\n",
       " 'height236',\n",
       " 'period236',\n",
       " 'direction236',\n",
       " 'hits_at236']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondary_columns=[]\n",
    "for i in range(1,hours):\n",
    "    j=i*2\n",
    "    secondary_columns.append(\"height\" + str(j))\n",
    "    secondary_columns.append(\"period\" + str(j))\n",
    "    secondary_columns.append(\"direction\" + str(j))\n",
    "    secondary_columns.append(\"hits_at\" + str(j))\n",
    "\n",
    "secondary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e410a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_url(buoy_url):\n",
    "    out = []\n",
    "    for line in urllib.request.urlopen(buoy_url):\n",
    "        l = line.decode('utf-8') #utf-8 or iso8859-1 or whatever the page encoding scheme is\n",
    "        row=[]\n",
    "        if \"Cycle\" in l:\n",
    "            regex = re.findall(r'Cycle.*:\\s+([0-9]+)\\s+([0-9]+)\\s+UTC.*', l)\n",
    "            if len(regex):\n",
    "                thedate=regex[0]\n",
    "        else:\n",
    "            res = re.match(r'.*[|]\\s+([0-9]+)\\s+([0-9]+)\\s+[|].*', l)\n",
    "            waves = re.findall(r'[|]\\s+([0-9\\.]+)\\s+([0-9\\.]+)\\s+([0-9]+)\\s+[|]', l)\n",
    "            if res is not None:\n",
    "                row.append(thedate)\n",
    "                row.append(res.groups())\n",
    "            if len(waves):\n",
    "                if len(waves) > 3:\n",
    "                    # print(\"found > 3 waves, reduce to 3\")\n",
    "                    waves = waves[:3]\n",
    "                b = []\n",
    "                list(b.extend(item) for item in waves)\n",
    "                row.append(b)\n",
    "                my = tuple(chain.from_iterable(row))\n",
    "                out.append(my)\n",
    "    return out, thedate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0c54672",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_columns=['pred_dtime', 'hour', 'pred_day', 'pred_hour', 'height1', 'period1', 'direction1', 'height2', \n",
    "         'period2', 'direction2', 'height3', 'period3', 'direction3'] \n",
    "\n",
    "def is_valid_swell_direction(direction):\n",
    "    if int(direction) > 180 or int(direction) < 20:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def best_height(row):\n",
    "    best_secondary=2\n",
    "    # Check which is best secondary swell - swell 2 or swell 3?\n",
    "    if row['direction3'] != None:\n",
    "        if is_valid_swell_direction(row['direction3']):\n",
    "            if is_valid_swell_direction(row['direction2']) == False :\n",
    "                best_secondary=3    \n",
    "    best_direction = \"direction\" + str(best_secondary)\n",
    "    best=1\n",
    "    # Check which is best of swell 1 and secondary swell ?\n",
    "    if row[best_direction] != None and is_valid_swell_direction(row[best_direction]) == True:\n",
    "        if is_valid_swell_direction(row['direction1']) == False:\n",
    "            best=best_secondary\n",
    "                \n",
    "    height = row['height' + str(best)]\n",
    "    period = row['period' + str(best)]\n",
    "    direction = row['direction' + str(best)]\n",
    "        \n",
    "    return pd.Series([height, period, direction])\n",
    "\n",
    "# feature engineering - estimate the time at which the swell arrives at Lahinch from buoy\n",
    "def estimate_hits_at(row):\n",
    "    # baseline estimate\n",
    "    hits_at = row['pred_dtime'] + row['hour_offset'] + timedelta(hours=8) \n",
    "    \n",
    "    if float(row['direction']) < 80 and float(row['direction']) > 66:\n",
    "        hits_at = hits_at - timedelta(hours=1)\n",
    "    if float(row['direction']) <= 66 and float(row['direction']) > 50:\n",
    "        hits_at = hits_at - timedelta(hours=2)\n",
    "    if float(row['direction']) <= 50 and float(row['direction']) > 20:\n",
    "        hits_at = hits_at - timedelta(hours=3)\n",
    "    if float(row['period']) > 12:\n",
    "        hits_at = hits_at - timedelta(hours=1)\n",
    "    \n",
    "    return pd.Series([hits_at])\n",
    "    \n",
    "\n",
    "if BACKFILL == True:\n",
    "    df = pd.read_csv(backfill_url, parse_dates=['hits_at', 'pred_dtime'])\n",
    "    num_rows = df.shape[0]\n",
    "    print(\"num_rows: \" + str(num_rows))\n",
    "    rows = []\n",
    "    for i in range(1, num_rows):\n",
    "        row=[]\n",
    "        for j in range(0, len(secondary_columns)):\n",
    "            row.append(\"\")\n",
    "        if i % 2 == 0:\n",
    "            rows.append(row)\n",
    "    df_secondary = pd.DataFrame(rows, columns=secondary_columns)\n",
    "    df = pd.concat([df, df_secondary],axis=1, join=\"outer\")    \n",
    "    \n",
    "else: # BACKFILL == False\n",
    "    res,thedate=process_url(url)\n",
    "    df = pd.DataFrame(res, columns=primary_columns)\n",
    "    df['pred_dtime'] = pd.to_datetime(df['pred_dtime'], format='%Y%m%d')\n",
    "    df.insert(loc=0, column=\"hour_offset\", value=(df.reset_index().index*2))\n",
    "    df['hour_offset'] = df.hour_offset.astype('timedelta64[h]')\n",
    "    df['pred_dtime'] = df['pred_dtime'] + df.hour.astype('timedelta64[h]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7636c633",
   "metadata": {},
   "outputs": [],
   "source": [
    "if BACKFILL == False:\n",
    "    df[['height','period','direction']]=df.apply(best_height, axis=1)\n",
    "    df[['hits_at']]=df.apply(estimate_hits_at, axis=1)\n",
    "    df['beach_id'] = 1\n",
    "    df.drop(['height1', 'period1', 'direction1', 'height2', 'period2', 'direction2', 'hour_offset',\n",
    "              'height3', 'period3', 'direction3','hour', 'pred_day', 'pred_hour'], axis=1, inplace=True) \n",
    "    df['height'] = pd.to_numeric(df['height'] , errors='coerce')\n",
    "    df['period'] = pd.to_numeric(df['period'] , errors='coerce')\n",
    "    df['direction'] = pd.to_numeric(df['direction'] , errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3490c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beach_id</th>\n",
       "      <th>pred_dtime</th>\n",
       "      <th>height</th>\n",
       "      <th>period</th>\n",
       "      <th>direction</th>\n",
       "      <th>hits_at</th>\n",
       "      <th>height2</th>\n",
       "      <th>period2</th>\n",
       "      <th>direction2</th>\n",
       "      <th>hits_at2</th>\n",
       "      <th>...</th>\n",
       "      <th>direction232</th>\n",
       "      <th>hits_at232</th>\n",
       "      <th>height234</th>\n",
       "      <th>period234</th>\n",
       "      <th>direction234</th>\n",
       "      <th>hits_at234</th>\n",
       "      <th>height236</th>\n",
       "      <th>period236</th>\n",
       "      <th>direction236</th>\n",
       "      <th>hits_at236</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-04 06:00:00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>8.4</td>\n",
       "      <td>145</td>\n",
       "      <td>2022-07-04 14:00:00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>8.3</td>\n",
       "      <td>144</td>\n",
       "      <td>1656950400000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>1657778400000000000</td>\n",
       "      <td>0.88</td>\n",
       "      <td>9.1</td>\n",
       "      <td>100</td>\n",
       "      <td>1657785600000000000</td>\n",
       "      <td>0.86</td>\n",
       "      <td>9.1</td>\n",
       "      <td>100</td>\n",
       "      <td>1657792800000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 478 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   beach_id          pred_dtime  height  period  direction  \\\n",
       "0         1 2022-07-04 06:00:00    0.97     8.4        145   \n",
       "\n",
       "              hits_at  height2  period2  direction2             hits_at2  ...  \\\n",
       "0 2022-07-04 14:00:00     0.95      8.3         144  1656950400000000000  ...   \n",
       "\n",
       "   direction232           hits_at232  height234  period234  direction234  \\\n",
       "0            97  1657778400000000000       0.88        9.1           100   \n",
       "\n",
       "            hits_at234  height236  period236  direction236  \\\n",
       "0  1657785600000000000       0.86        9.1           100   \n",
       "\n",
       "            hits_at236  \n",
       "0  1657792800000000000  \n",
       "\n",
       "[1 rows x 478 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = [\"height\", \"period\", \"direction\", \"hits_at\"]\n",
    "\n",
    "if BACKFILL == False:\n",
    "    entry = []\n",
    "    data = []\n",
    "    for index, row in df.iterrows():\n",
    "        if (index==0):\n",
    "            data.append(row['beach_id'])\n",
    "            data.append(row['pred_dtime'])\n",
    "        if (index < hours):\n",
    "            for m in matches:\n",
    "                data.append(row[m])\n",
    "\n",
    "    entry.append(data)\n",
    "    first_columns=['beach_id', 'pred_dtime', 'height', 'period', 'direction', 'hits_at']    \n",
    "    all_columns = first_columns + secondary_columns\n",
    "    df2 = pd.DataFrame(entry, columns=all_columns)\n",
    "else:    \n",
    "    df2=df\n",
    "\n",
    "for i in range(1,hours):\n",
    "    for j in matches:\n",
    "#         if j.startswith(\"hits_at\") and BACKFILL==False:\n",
    "#             df2[j+str(i*2)] = pd.to_datetime(df2[j+str(i*2)])    \n",
    "#         else:\n",
    "      df2[j+str(i*2)] = pd.to_numeric(df2[j+str(i*2)])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "671ea0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/135\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bc6ed56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/135/jobs/named/swells_exploded_10_offline_fg_backfill/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x7fe257e29ca0>, None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swells_fg = fs.get_or_create_feature_group(name=\"swells_exploded\",\n",
    "                version=version,\n",
    "                primary_key=[\"beach_id\"],\n",
    "                event_time=\"hits_at\",\n",
    "                description=\"Buoy surf height predictions\",\n",
    "                online_enabled=True,\n",
    "                statistics_config={\"enabled\": True, \"histograms\": True, \"correlations\": True}\n",
    "                )\n",
    "swells_fg.insert(df2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99fac1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
