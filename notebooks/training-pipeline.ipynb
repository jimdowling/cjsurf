{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "537f2f7d",
   "metadata": {},
   "source": [
    "## Creates the `lahinch_surf` feature view, trains the `cjsurf_model`\n",
    "\n",
    "This training pipeline can be in Google Colab or a Jupyter notebook.\n",
    "\n",
    "### Requirements\n",
    "\n",
    " * hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d96f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import hsfs\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892fdd54",
   "metadata": {},
   "source": [
    "### Not app.hopsworks.ai ?\n",
    "\n",
    "If you are running your own Hopsworks cluster (not app.hopsworks.ai):\n",
    "\n",
    " * uncomment the cell below\n",
    " * fill in details for your cluster\n",
    " * run the cel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c69ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this cell and fill in details if you are running your own Hopsworks cluster\n",
    "#!echo \"xxxx\" > api-key.txt\n",
    "# key=\"\"\n",
    "# with open(\"api-key.txt\", \"r\") as f:\n",
    "#     key = f.read().rstrip()\n",
    "# os.environ['HOPSWORKS_PROJECT']=\"cjsurf\"\n",
    "# os.environ['HOPSWORKS_HOST']=\"35.187.178.84\"\n",
    "# os.environ['HOPSWORKS_API_KEY']=key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cac2729",
   "metadata": {},
   "source": [
    "### Connect to your Hopsworks cluster\n",
    "\n",
    "If you only set the HOPSWORKS_API_KEY, it will assume you are connecting to app.hopsworks.ai.\n",
    "Set HOPSWORKS_HOST and HOPSWORKS_PROJECT environment variables to connect to a different Hopsworks cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7034be",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083f646b",
   "metadata": {},
   "source": [
    "### Online Transformations for input features\n",
    "\n",
    "Normalize the numerical input features (`height`, `period`, `direction`) with HSFS built-in `standard_scalar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b4357",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours=119\n",
    "\n",
    "standard_scaler = fs.get_transformation_function(name=\"standard_scaler\")\n",
    "\n",
    "transformation_functions = {\n",
    "    \"height\": standard_scaler,\n",
    "    \"period\": standard_scaler,\n",
    "    \"direction\": standard_scaler,\n",
    "}\n",
    "for i in range(1,hours):\n",
    "    transformation_functions[\"height\" + str(i*2)]=standard_scaler\n",
    "    transformation_functions[\"period\" + str(i*2)]=standard_scaler\n",
    "    transformation_functions[\"direction\" + str(i*2)]=standard_scaler    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f21635",
   "metadata": {},
   "source": [
    "## Select features for the Feature View\n",
    "\n",
    "Join the `wave_height` from `lahinch` feature group with all of the features from the `swells_exploded` feature group. \n",
    "\n",
    "The `query` object can be inspected - `show` rows, `read` to get a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e2b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lahinch_fg = fs.get_feature_group(\"lahinch\", version=1)\n",
    "swells_fg = fs.get_feature_group(\"swells_exploded\", version=1)\n",
    "query = lahinch_fg.select(['wave_height']).join(\n",
    "    swells_fg.select_except(['beach_id'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411a2814",
   "metadata": {},
   "source": [
    "### Get or create the `lahinch_surf` feature view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e467395",
   "metadata": {},
   "outputs": [],
   "source": [
    "version=1\n",
    "try: \n",
    "    fv = fs.get_feature_view(\"lahinch_surf\", version=version)\n",
    "except:\n",
    "    fv = fs.create_feature_view(name='lahinch_surf', \n",
    "                            description=\"Lahinch surf height prediction features\",\n",
    "                            version=version,\n",
    "                            labels=[\"wave_height\"],\n",
    "                            query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23b1202",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "td_version=1\n",
    "\n",
    "#X_train,y_train,X_test,y_test = fv.train_test_split(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc68744",
   "metadata": {},
   "source": [
    "### Create training data as files with the `lahinch_surf` feature view\n",
    "\n",
    "This will run a Spark job on Hopsworks that will join the features together and write them out as a `csv` file in Hopsworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca67c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "td_version, td_job = fv.create_train_test_split(\n",
    "    description = 'cjsurf training data',\n",
    "    data_format = 'csv',\n",
    "    test_size = 0.1,\n",
    "    version=td_version,\n",
    "    write_options = {'wait_for_job': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec3f6cb",
   "metadata": {},
   "source": [
    "### Read your Training Data as Pandas DataFrames\n",
    "You can read back the training data as Pandas Dataframes - here split into train/test sets, with `X_` storing the features and `y_` the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e86f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = fv.get_train_test_split(td_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9aa2ad",
   "metadata": {},
   "source": [
    "Not all of the features are needed for training - only the height, period, direction of the swells with a `hits_at` timestamp that is closest to, but before the observation of the `surf_height`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd3fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[['height', 'period', 'direction']]\n",
    "X_test = X_test[['height', 'period', 'direction']]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3930f",
   "metadata": {},
   "source": [
    "Encode the label (`wave_height`) in both the train and test DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe7e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train_encoded=le.fit_transform(y_train['wave_height'])\n",
    "y_test_encoded=le.fit_transform(y_test['wave_height'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55409905",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "Using k-nearest neighbors in Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069aa94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train,y_train_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b69bd9",
   "metadata": {},
   "source": [
    "### Evaluate the Model\n",
    "\n",
    "On our test set, calculate the classification scores: precision, recall, fscore.\n",
    "It may also be useful to calculate the rmse to see how close all the predictions were to the true wave_heights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support, mean_squared_error\n",
    "%matplotlib inline\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(\n",
    "    y_test_encoded, y_pred, average=\"weighted\", zero_division=1)\n",
    "\n",
    "rmse = mean_squared_error(y_test_encoded, y_pred)\n",
    "\n",
    "# We model surf height prediction as a classification problem, as there\n",
    "# only a small number of heights reported on Lahinch beach, but the RMSE\n",
    "# is still a useful metric for evaluating if your model is more accurate or not\n",
    "metrics = {\n",
    "    \"precision\" : precision,\n",
    "    \"recall\" : recall,\n",
    "    \"fscore\" : fscore,\n",
    "    \"rmse\" : rmse\n",
    "}\n",
    "\n",
    "error_rates = []\n",
    "num_samples=len(y_pred)\n",
    "for a in range(1, num_samples):\n",
    "    error_rates.append(np.mean(y_test_encoded[a] - y_pred))\n",
    "\n",
    "plt.plot(range(0,num_samples), y_pred, label=\"predicted\")\n",
    "plt.plot(range(0,num_samples), y_test_encoded, label=\"actual\")\n",
    "plt.title('Surf height predictions')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Height')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b5c29f",
   "metadata": {},
   "source": [
    "## Register the model with Hopsworks Model Registry\n",
    "\n",
    "The model registry stores your model for later use in inference.\n",
    "\n",
    "Here, we also specify the model input/output schema using the DataFrame containing the training features.\n",
    "We also send a dict containing the `metrics` computed in the last cell, as these will be shown for the model in the registry. \n",
    "\n",
    "We can also include a sample to enable a deployed model to be easily tested in the UI. The sample will be stored in the model registry, and when you create a deployment with the model, there is a `Test Model` UI button which will send that sample to the model for scoring, returning the result. It is useful for debugging models.\n",
    "\n",
    "Here, we are creating a `mr.python` model for Scikit-Learn. There is also a `mr.tf` model available for TensorFlow models.\n",
    "When you call `save()` on the model returned by HSML, it uploads the model and any artifacts to Hopsworks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9588cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hsml.schema import Schema\n",
    "from hsml.model_schema import ModelSchema\n",
    "\n",
    "project = hopsworks.login()\n",
    "\n",
    "mr = project.get_model_registry()\n",
    "    \n",
    "joblib.dump(model,'knn_model.pkl')\n",
    "\n",
    "input_example = X_train.sample()\n",
    "input_schema = Schema(X_train)\n",
    "output_schema = Schema(y_train)\n",
    "model_schema = ModelSchema(input_schema, output_schema)\n",
    "\n",
    "knn_model = mr.python.create_model(\n",
    "    version=1,\n",
    "    name=\"cjsurf\", \n",
    "    metrics=metrics,\n",
    "    model_schema=model_schema,\n",
    "    input_example=input_example, description=\"Lahinch Surf height predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36698d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile knn_model/cjsurf_predictor.py\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "class Predict(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # NOTE: env var ARTIFACT_FILES_PATH has the local path to the model artifact files        \n",
    "        self.model = joblib.load(os.environ[\"ARTIFACT_FILES_PATH\"] + \"/knn_model.pkl\")\n",
    "\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\" Serves a prediction request from a trained model\"\"\"\n",
    "        return self.model.predict(inputs).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e46368",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model.save(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd5d1cc",
   "metadata": {},
   "source": [
    "### Create and start a model deployment\n",
    "\n",
    "You can now create a deployment from the model. \n",
    "Call `start()` on the model deployment to start it running on KServe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef98aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_script_path = knn_model.version_path + \"/cjsurf_predictor.py\"\n",
    "\n",
    "model_deployment = knn_model.deploy(name=\"cjsurf\",\n",
    "                                    model_server=\"PYTHON\",\n",
    "                                    script_file=predictor_script_path,\n",
    "                                    serving_tool=\"KSERVE\"\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f278f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deployment.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77be9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
