{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd508f27",
   "metadata": {},
   "source": [
    "## Feature Pipeline for the `lahinch` feature group\n",
    "\n",
    "This feature pipeline can be run on a schedule using github actions (see github repo for the example file).\n",
    "\n",
    "### Requirements\n",
    "\n",
    " * hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb1e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26b6672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import parsedatetime\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import requests\n",
    "import hopsworks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b728c7",
   "metadata": {},
   "source": [
    "### Not app.hopsworks.ai ?\n",
    "\n",
    "If you are running your own Hopsworks cluster (not app.hopsworks.ai):\n",
    "\n",
    " * uncomment the cell below\n",
    " * fill in details for your cluster\n",
    " * run the cel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0fd886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this cell and fill in details if you are running your own Hopsworks cluster\n",
    "# key=\"\"\n",
    "# with open(\"api-key.txt\", \"r\") as f:\n",
    "#     key = f.read().rstrip()\n",
    "# os.environ['HOPSWORKS_PROJECT']=\"cjsurf\"\n",
    "# os.environ['HOPSWORKS_HOST']=\"35.187.178.84\"\n",
    "# os.environ['HOPSWORKS_API_KEY']=key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894fd541",
   "metadata": {},
   "source": [
    "### Backfill the feature group \n",
    "\n",
    "If you set `BACKFILL` to `True` in the cell below, and continue running all the cells, you will insert surf height observations from the `lahinch-surf.csv` file into the `lahinch` feature group.\n",
    "\n",
    "When `BACKFILL` is `False`, it will download the latest surf report from Lahinch Surf Shop and insert it into the `lahinch` feature group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8efbdc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKFILL=False\n",
    "if os.environ.get('CJSURF_BACKFILL') == \"False\":\n",
    "    BACKFILL=False\n",
    "version=1\n",
    "url=\"https://www.lahinchsurfshop.com/\"\n",
    "backfill_url=\"https://repo.hops.works/master/hopsworks-tutorials/data/cjsurf/lahinch-surf.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4757e60c",
   "metadata": {},
   "source": [
    "When `BACkFILL` is `False`, we scrape the surf height for today from the Lahinch surf shop webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d64e0607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_time</th>\n",
       "      <th>wave_height</th>\n",
       "      <th>max_height</th>\n",
       "      <th>min_height</th>\n",
       "      <th>beach_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-21 10:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     observation_time  wave_height  max_height  min_height  beach_id\n",
       "0 2022-08-21 10:00:00          2.0         2.0         2.0         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if BACKFILL == False:\n",
    "    filepath = 'index.html'\n",
    "    if os.path.exists(filepath):\n",
    "        os.remove(filepath)\n",
    "    response = requests.get(url)\n",
    "    open(filepath, \"wb\").write(response.content)    \n",
    "\n",
    "    cal = parsedatetime.Calendar()\n",
    "    data = []\n",
    "    with open(filepath) as fp:\n",
    "        line = fp.readline()\n",
    "        cnt = 1\n",
    "        the_date = None\n",
    "        img_url = None\n",
    "        max_height = None\n",
    "        min_height = None\n",
    "        regex = None\n",
    "        while line:\n",
    "            if \"Last updated\" in line:\n",
    "                #: June 13, 2022\n",
    "                str = line.partition(\"Last updated</b>:\")[2]\n",
    "                date_str = str.partition(\"</p>\")[0]\n",
    "                # fix the time to 10am\n",
    "                date_str = date_str + \" 10am\"\n",
    "                time_struct, parse_status = cal.parse(date_str)\n",
    "                the_date = datetime(*time_struct[:6])\n",
    "            if \"Wave height\" in line:\n",
    "                str = line.partition(\"Wave height</b>:\")[2]\n",
    "                height_str = str.partition(\", Sea\")[0]\n",
    "                regex = re.match(r'.*([0-9]+)-([0-9]+)ft.*', height_str)\n",
    "                if regex is not None:\n",
    "                    min_height=regex.groups()[0]\n",
    "                    max_height=regex.groups()[1]\n",
    "                    height = (float(min_height)+float(max_height))/2\n",
    "                else:\n",
    "                    regex = re.findall(r'.*([0-9]+)ft', height_str)\n",
    "                    if len(regex):\n",
    "                        max_height=regex[0]\n",
    "                        min_height=regex[0]\n",
    "                        height=regex[0]\n",
    "                    else:\n",
    "                        regex = re.findall(r'.*([4-9]+)inches', height_str)\n",
    "                        if len(regex):\n",
    "                            max_height=\"0.5\"\n",
    "                            min_height=\"0\"\n",
    "                            height=\"0.5\"\n",
    "                        else:\n",
    "                            max_height=\"0\"\n",
    "                            min_height=\"0\"\n",
    "                            height=\"0\"\n",
    "                    \n",
    "            if regex is not None:\n",
    "                if the_date is not None:\n",
    "                    row=[the_date, height, max_height, min_height]\n",
    "                    data.append(row)\n",
    "                    the_date = None\n",
    "                    regex = None\n",
    "            line = fp.readline()\n",
    "            cnt += 1\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['observation_time', 'wave_height', 'max_height', 'min_height'])\n",
    "    df['beach_id'] = 1\n",
    "    \n",
    "else: # BACKFILL == True\n",
    "    df = pd.read_csv(backfill_url, parse_dates=['observation_time'])\n",
    "\n",
    "df['wave_height'] = pd.to_numeric(df['wave_height'] , errors='coerce').astype(np.float64)\n",
    "df['max_height'] = pd.to_numeric(df['max_height'] , errors='coerce').astype(np.float64)\n",
    "df['min_height'] = pd.to_numeric(df['min_height'] , errors='coerce').astype(np.float64)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55a48ab",
   "metadata": {},
   "source": [
    "## Validate your feature data\n",
    "\n",
    "We add a validation rule here that the `wave_height` should not be lower than `0` or greater than `20` feet high.\n",
    "\n",
    "In the `lahinch` feature group user interface, you will see the results of the data ingestions and if this data validation rule passed for all ingestions or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e0c9d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "\n",
    "expectation_suite = ge.core.ExpectationSuite(expectation_suite_name=\"surf_height\")\n",
    "\n",
    "expectation_suite.add_expectation(\n",
    "  ge.core.ExpectationConfiguration(\n",
    "  expectation_type=\"expect_column_values_to_be_between\",\n",
    "  kwargs={\"column\":\"wave_height\", \"min_value\": 0, \"max_value\": 20}) \n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149ad0d6",
   "metadata": {},
   "source": [
    "### Connect to your Hopsworks cluster\n",
    "\n",
    "If you only set the HOPSWORKS_API_KEY, it will assume you are connecting to app.hopsworks.ai.\n",
    "Set HOPSWORKS_HOST and HOPSWORKS_PROJECT environment variables to connect to a different Hopsworks cluster.\n",
    "\n",
    "Then write your DataFrame to the `lahinch` feature group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6091678d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/398\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "2022-08-21 16:30:10,460 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/398/fs/335/fg/630\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1c9ea37e2e44a6a31f39c5456ee3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/1 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/398/jobs/named/lahinch_1_offline_fg_backfill/executions\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login()\n",
    "\n",
    "fs = project.get_feature_store()\n",
    "lahinch_fg = fs.get_or_create_feature_group(name=\"lahinch\",\n",
    "        description=\"Lahinch beach surf height observations\",\n",
    "        version=version,\n",
    "        primary_key=[\"beach_id\"],\n",
    "        event_time=\"observation_time\",\n",
    "        expectation_suite=expectation_suite,\n",
    "        statistics_config={\"enabled\": True, \"histograms\": True, \"correlations\": True}\n",
    "        )\n",
    "\n",
    "_, _ = lahinch_fg.insert(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f327f4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
