{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d27febb",
   "metadata": {},
   "source": [
    "## Runs the batch prediction pipeline \n",
    "\n",
    "Writes predictions to `wave_predictions` feature group, creates a PNG with the surf height predictions, and uploads it to Hopsworks.\n",
    "\n",
    "### Requirements\n",
    "\n",
    " * hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a01606",
   "metadata": {},
   "source": [
    "### Not app.hopsworks.ai ?\n",
    "\n",
    "If you are running your own Hopsworks cluster (not app.hopsworks.ai):\n",
    "\n",
    " * uncomment the cell below\n",
    " * fill in details for your cluster\n",
    " * run the cel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b0347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this cell and fill in details if you are running your own Hopsworks cluster\n",
    "# key=\"\"\n",
    "# with open(\"api-key.txt\", \"r\") as f:\n",
    "#     key = f.read().rstrip()\n",
    "# os.environ['HOPSWORKS_PROJECT']=\"cjsurf\"\n",
    "# os.environ['HOPSWORKS_HOST']=\"35.187.178.84\"\n",
    "# os.environ['HOPSWORKS_API_KEY']=key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d840e9",
   "metadata": {},
   "source": [
    "### Connect to your Hopsworks cluster\n",
    "\n",
    "If you only set the HOPSWORKS_API_KEY, it will assume you are connecting to app.hopsworks.ai.\n",
    "Set HOPSWORKS_HOST and HOPSWORKS_PROJECT environment variables to connect to a different Hopsworks cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e5e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c675069",
   "metadata": {},
   "source": [
    "### Download the model from the model registry\n",
    "\n",
    "Then read the pickled file and unpickle the serialized object into the model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93edc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr = project.get_model_registry()\n",
    "model = mr.get_model(\"cjsurf\", version=1)\n",
    "model_dir = model.download()\n",
    "model = joblib.load(model_dir + \"/knn_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024407eb",
   "metadata": {},
   "source": [
    "### Get a reference to the feature view\n",
    "\n",
    "You need to initialize the feature view with a training data version if the feature view has transformations, as transformations need to know which training data statistics to use for normalization, encoding, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b4357",
   "metadata": {},
   "outputs": [],
   "source": [
    "fv = fs.get_feature_view(\"lahinch_surf\", version=1)\n",
    "fv.init_serving(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d9597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fv.keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7787f6",
   "metadata": {},
   "source": [
    "### Retreive the feature vector\n",
    "\n",
    "It comes back as a Python array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b735e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = {\"beach_id\" : 1}\n",
    "vector = fv.get_feature_vector(key)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e61630",
   "metadata": {},
   "source": [
    "### Refactor the feature vector\n",
    "\n",
    "We are going to make 119 predictions with the vector for hour=0, hour=2, .., hour=338.\n",
    "\n",
    "Each prediction for hour=X is made using a feature vector containing features from the swell:\n",
    "\n",
    " * height\n",
    " * period\n",
    " * direction\n",
    " \n",
    "Here, we have to extract the 119 feature vectors from the Python array returned from the feature store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb0811",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors = []\n",
    "# Remove the 'pred_dtime' column\n",
    "feature_vectors.append(vector[0:3])\n",
    "for i in range(4,len(vector),4):\n",
    "    feature_vectors.append(vector[i:i+3])\n",
    "dt = vector[3] # 'pred_dtime'\n",
    "feature_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f549c595",
   "metadata": {},
   "source": [
    "### Make  surf height predictions\n",
    "\n",
    "119 predictions for hour=0, hour=2, ..., hour=338.\n",
    "\n",
    "Store the predictions in `row_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e198c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_list=[]\n",
    "columns=[\"beach_id\",\"hits_at\", \"wave_height\"]\n",
    "for i in range(0,len(feature_vectors)):\n",
    "    arr=[]\n",
    "    arr.append(feature_vectors[i])\n",
    "    res = model.predict(arr)\n",
    "    row = []\n",
    "    row.append(1) #beach_id\n",
    "    hour = datetime.timedelta(0, (1*3600*i*2))\n",
    "    ts = dt + hour\n",
    "    dt_str = ts.strftime(\"%Y-%m-%d %H:%M\") #:%S\n",
    "    row.append(dt_str)\n",
    "    row.append(res[0])\n",
    "    row_list.append(row)\n",
    "\n",
    "df = pd.DataFrame(row_list, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6571e77a",
   "metadata": {},
   "source": [
    "### Insert the predictions into the feature group\n",
    "\n",
    "Store the predictions for later analysis, feature monitoring, model performance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a61ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = project.get_feature_store()\n",
    "\n",
    "preds_fg = fs.get_or_create_feature_group(name=\"wave_predictions\",\n",
    "                version=1,\n",
    "                primary_key=[\"beach_id\", \"hits_at\"],\n",
    "                description=\"Lahinch surf height predictions\",\n",
    "                online_enabled=True\n",
    "                )\n",
    "preds_fg.insert(df)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64b9aaf",
   "metadata": {},
   "source": [
    "### Create PNG file with the surf height predictions\n",
    "\n",
    "Use plotly to create a chart with the surf height predictions. Upload it to the Resources directory in your project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ab0f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.line(df, x = \"hits_at\", y = \"wave_height\", \n",
    "              #markers=True, \n",
    "              title = \"Wave Heights at Lahinch\"\n",
    "             )\n",
    "fig.update_layout(\n",
    "#    plot_bgcolor=\"white\",\n",
    "    margin=dict(t=50,l=10,b=10,r=10)\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_tickformat = '%d/%m (%a)<br>Time %h:%m <br> %Y'\n",
    ")\n",
    "\n",
    "fig.update_layout()\n",
    "\n",
    "fig.update_xaxes(\n",
    "        ticks=\"outside\", \n",
    "        tickwidth=2,\n",
    "        tickcolor='black',\n",
    "        ticklen=10,\n",
    "        title_text = \"Time\",\n",
    "        title_font = {\"size\": 36},\n",
    "        title_standoff = 25)\n",
    "fig.update_yaxes(\n",
    "        title_text = \"Wave Height (ft)\",\n",
    "        title_font = {\"size\": 36},\n",
    "        title_standoff = 25,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "        font=dict(\n",
    "          family=\"Time\",\n",
    "          size=24,\n",
    "          color=\"black\"\n",
    "        )\n",
    ")\n",
    "\n",
    "filename=\"../latest_lahinch.png\"\n",
    "fig.write_image(file=filename, format=\"png\", width=1920, height=1280)\n",
    "dataset_api = project.get_dataset_api()\n",
    "uploaded_file_path = dataset_api.upload(filename, \"Resources\", overwrite=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac2cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update images with predictions of previous week and outcomes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
