{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d27febb",
   "metadata": {},
   "source": [
    "## Runs the batch prediction pipeline \n",
    "\n",
    "Writes predictions to `wave_predictions` feature group, creates a PNG with the surf height predictions, and uploads it to Hopsworks.\n",
    "\n",
    "### Requirements\n",
    "\n",
    " * hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be02aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsworks\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a01606",
   "metadata": {},
   "source": [
    "### Not app.hopsworks.ai ?\n",
    "\n",
    "If you are running your own Hopsworks cluster (not app.hopsworks.ai):\n",
    "\n",
    " * uncomment the cell below\n",
    " * fill in details for your cluster\n",
    " * run the cel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b0347d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this cell and fill in details if you are running your own Hopsworks cluster\n",
    "# key=\"\"\n",
    "# with open(\"api-key.txt\", \"r\") as f:\n",
    "#     key = f.read().rstrip()\n",
    "# os.environ['HOPSWORKS_PROJECT']=\"cjsurf\"\n",
    "# os.environ['HOPSWORKS_HOST']=\"35.187.178.84\"\n",
    "# os.environ['HOPSWORKS_API_KEY']=key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d840e9",
   "metadata": {},
   "source": [
    "### Connect to your Hopsworks cluster\n",
    "\n",
    "If you only set the HOPSWORKS_API_KEY, it will assume you are connecting to app.hopsworks.ai.\n",
    "Set HOPSWORKS_HOST and HOPSWORKS_PROJECT environment variables to connect to a different Hopsworks cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "838e5e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/398\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c675069",
   "metadata": {},
   "source": [
    "### Download the model from the model registry\n",
    "\n",
    "Then read the pickled file and unpickle the serialized object into the model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c93edc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    },
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/398/modelregistries/398/models/cjsurf_model_1). Server response: \nHTTP code: 404, HTTP reason: Not Found, error code: 360000, error msg: No model found for provided name and version., user msg: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_370072/4203211735.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_registry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cjsurf_model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/knn_model.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/hsml/model_registry.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(self, name, version)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_VERSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         return self._model_api.get(\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/hsml/core/model_api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, name, version, model_registry_id, shared_registry_project_name)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mquery_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"expand\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"trainingdatasets\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mmodel_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_response_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/hsml/decorators.py\u001b[0m in \u001b[0;36mif_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNoHopsworksConnectionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mif_connected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/hsml/client/base.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRestAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/398/modelregistries/398/models/cjsurf_model_1). Server response: \nHTTP code: 404, HTTP reason: Not Found, error code: 360000, error msg: No model found for provided name and version., user msg: "
     ]
    }
   ],
   "source": [
    "mr = project.get_model_registry()\n",
    "model = mr.get_model(\"cjsurf\", version=1)\n",
    "model_dir = model.download()\n",
    "model = joblib.load(model_dir + \"/knn_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024407eb",
   "metadata": {},
   "source": [
    "### Get a reference to the feature view\n",
    "\n",
    "You need to initialize the feature view with a training data version if the feature view has transformations, as transformations need to know which training data statistics to use for normalization, encoding, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b4357",
   "metadata": {},
   "outputs": [],
   "source": [
    "fv = fs.get_feature_view(\"lahinch_surf\", version=1)\n",
    "fv.init_serving(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7787f6",
   "metadata": {},
   "source": [
    "### Retreive the feature vector\n",
    "\n",
    "It comes back as a Python array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b735e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = {\"beach_id\" : 1}\n",
    "vector = fv.get_feature_vector(key)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e61630",
   "metadata": {},
   "source": [
    "### Refactor the feature vector\n",
    "\n",
    "We are going to make 119 predictions with the vector for hour=0, hour=2, .., hour=338.\n",
    "\n",
    "Each prediction for hour=X is made using a feature vector containing features from the swell:\n",
    "\n",
    " * height\n",
    " * period\n",
    " * direction\n",
    " \n",
    "Here, we have to extract the 119 feature vectors from the Python array returned from the feature store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb0811",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vectors = []\n",
    "# Remove the 'pred_dtime' column\n",
    "feature_vectors.append(vector[0:3])\n",
    "for i in range(4,len(vector),4):\n",
    "    feature_vectors.append(vector[i:i+3])\n",
    "dt = vector[3] # 'pred_dtime'\n",
    "feature_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f549c595",
   "metadata": {},
   "source": [
    "### Make  surf height predictions\n",
    "\n",
    "119 predictions for hour=0, hour=2, ..., hour=338.\n",
    "\n",
    "Store the predictions in `row_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e198c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_list=[]\n",
    "columns=[\"beach_id\",\"hits_at\", \"wave_height\"]\n",
    "for i in range(0,len(feature_vectors)):\n",
    "    arr=[]\n",
    "    arr.append(feature_vectors[i])\n",
    "    res = model.predict(arr)\n",
    "    row = []\n",
    "    row.append(1) #beach_id\n",
    "    hour = datetime.timedelta(0, (1*3600*i*2))\n",
    "    ts = dt + hour\n",
    "    dt_str = ts.strftime(\"%Y-%m-%d %H:%M\") #:%S\n",
    "    row.append(dt_str)\n",
    "    row.append(res[0])\n",
    "    row_list.append(row)\n",
    "\n",
    "df = pd.DataFrame(row_list, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6571e77a",
   "metadata": {},
   "source": [
    "### Insert the predictions into the feature group\n",
    "\n",
    "Store the predictions for later analysis, feature monitoring, model performance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a61ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = project.get_feature_store()\n",
    "\n",
    "preds_fg = fs.get_or_create_feature_group(name=\"wave_predictions\",\n",
    "                version=1,\n",
    "                primary_key=[\"beach_id\", \"hits_at\"],\n",
    "                description=\"Lahinch surf height predictions\",\n",
    "                online_enabled=True\n",
    "                )\n",
    "preds_fg.insert(df)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64b9aaf",
   "metadata": {},
   "source": [
    "### Create PNG file with the surf height predictions\n",
    "\n",
    "Use plotly to create a chart with the surf height predictions. Upload it to the Resources directory in your project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ab0f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.line(df, x = \"hits_at\", y = \"wave_height\", \n",
    "              #markers=True, \n",
    "              title = \"Wave Heights at Lahinch\"\n",
    "             )\n",
    "fig.update_layout(\n",
    "#    plot_bgcolor=\"white\",\n",
    "    margin=dict(t=50,l=10,b=10,r=10)\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_tickformat = '%d/%m (%a)<br>Time %h:%m <br> %Y'\n",
    ")\n",
    "\n",
    "fig.update_layout()\n",
    "\n",
    "fig.update_xaxes(\n",
    "        ticks=\"outside\", \n",
    "        tickwidth=2,\n",
    "        tickcolor='black',\n",
    "        ticklen=10,\n",
    "        title_text = \"Time\",\n",
    "        title_font = {\"size\": 36},\n",
    "        title_standoff = 25)\n",
    "fig.update_yaxes(\n",
    "        title_text = \"Wave Height (ft)\",\n",
    "        title_font = {\"size\": 36},\n",
    "        title_standoff = 25,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "        font=dict(\n",
    "          family=\"Time\",\n",
    "          size=24,\n",
    "          color=\"black\"\n",
    "        )\n",
    ")\n",
    "\n",
    "filename=\"../latest_lahinch.png\"\n",
    "fig.write_image(file=filename, format=\"png\", width=1920, height=1280)\n",
    "dataset_api = project.get_dataset_api()\n",
    "uploaded_file_path = dataset_api.upload(filename, \"Resources\", overwrite=True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac2cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: update images with predictions of previous week and outcomes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
